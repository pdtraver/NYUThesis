{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab73b4a",
   "metadata": {},
   "source": [
    "# Main Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "##import 12-TET pitch set data -- already curated as a set\n",
    "FULL_PITCH_SETS = 'full_pitch_sets.txt'\n",
    "\n",
    "##format pitch sets: create an array filled with each pitch set\n",
    "def create_pitch_sets(sets_filename):\n",
    "    with open(sets_filename) as file:\n",
    "        lines = [set(line.rstrip()) for line in file]\n",
    "    return lines\n",
    "\n",
    "##build the backbone of the markov model -- distance matrix with probabilities based on \n",
    "##intersection of pitch classes; normalize to sum to 1; cumulative sum to prepare for random\n",
    "##walk\n",
    "def create_distance_matrix(pitch_sets):\n",
    "    distance_matrix = []\n",
    "    for i in range(len(pitch_sets)):\n",
    "        row = []\n",
    "        for j in range(len(pitch_sets)):\n",
    "            row.append(len(pitch_sets[i].intersection(pitch_sets[j])))\n",
    "        row_sum = sum(row)\n",
    "        row = np.array(row,dtype='f')/row_sum\n",
    "        row = np.cumsum(row)\n",
    "        distance_matrix.append(list(row))\n",
    "    return(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##main drunkards walking music code\n",
    "\n",
    "##Inputs: list of pitch sets; distance matrix (of probabilities)\n",
    "##Function: randomly chooses a starting point; searches starting node's distance row and\n",
    "##          chooses next node based on probabilities\n",
    "##Output: an array documenting the random walk across the markov space\n",
    "\n",
    "##Note: ITERATIONS is a global variable; could be converted into an input\n",
    "ITERATIONS = 8\n",
    "\n",
    "def create_drunkards_walking_music(pitch_sets, distance_matrix):\n",
    "    current_set = random.randint(0,len(pitch_sets)-1)\n",
    "    drunkards_walking_music = [pitch_sets[current_set]]\n",
    "    for i in range(ITERATIONS):\n",
    "        r = random.uniform(0,1)\n",
    "        j = 0\n",
    "        while distance_matrix[current_set][j] < r:\n",
    "            j +=1\n",
    "        drunkards_walking_music.append(list(pitch_sets[j]))\n",
    "        current_set = j\n",
    "    return(drunkards_walking_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Composition helper functions\n",
    "\n",
    "##Array of frequency values (will be helpful later)\n",
    "FREQUENCY_VALUES = [\n",
    "    261.626,\n",
    "    277.183,\n",
    "    293.665,\n",
    "    311.127,\n",
    "    329.628,\n",
    "    349.228,\n",
    "    369.994,\n",
    "    391.995,\n",
    "    415.305,\n",
    "    440,\n",
    "    466.164,\n",
    "    493.883\n",
    "]\n",
    "\n",
    "##Self defined flatten function for ease of use\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE SOUND\n",
    "\n",
    "##INPUT: a pitch set, its octave displacement (fraction or int), a duration (as an integer),\n",
    "##       sampling frequency and a number of harmonics\n",
    "##FUNCTION: - randomly choose one element of the pitch set\n",
    "##          - convert pitch set from string to an array of ints\n",
    "##          - create time vector length of'duration' seconds with 'fs' samples per second\n",
    "##          - create fundamental oscillator by converting pitch class into frequency value\n",
    "##          - add overtone oscillators following same process but increase octave and decrease\n",
    "##            amplitude\n",
    "##          - sum these oscillators together to create a complex tone\n",
    "##OUTPUT: an np.array representing a sum of oscillators within the pitch set\n",
    "\n",
    "##NOTE: okay I think the 'lift' component of the overtones is wrong; it's adding octave way too\n",
    "##      fast, which I think will cause aliasing. I don't think aliased tones necessarily\n",
    "##      continue to exist in the pitch set -- THIS HAS TO BE FIXED\n",
    "##\n",
    "##      Second note: zip(*) takes each element of the oscillators and zips them into tuples\n",
    "##                   this allows the element-wise summation to happen at the return of the function\n",
    "def create_sound(pitch_set, octave, duration, fs, harmonics):\n",
    "    pitch = random.sample(pitch_set, k=1)[0]\n",
    "        \n",
    "    if pitch == 'A':\n",
    "        pitch = 10\n",
    "    elif pitch == 'B':\n",
    "        pitch = 11\n",
    "    else:\n",
    "        pitch = int(pitch)\n",
    "            \n",
    "    time = np.arange(0, duration, 1/fs)\n",
    "    \n",
    "    #fundamental\n",
    "    fundamental = np.cos(2*np.pi*octave*FREQUENCY_VALUES[pitch]*time)\n",
    "    \n",
    "    #harmonics\n",
    "    lift = 1\n",
    "    amp = 1\n",
    "    overtones = []\n",
    "    for i in range(harmonics):\n",
    "        over_pitch = random.sample(pitch_set, k=1)[0]\n",
    "        \n",
    "        if over_pitch == 'A':\n",
    "            over_pitch = 10\n",
    "        elif pitch == 'B':\n",
    "            over_pitch = 11\n",
    "        else:\n",
    "            over_pitch = int(pitch)\n",
    "        \n",
    "        amp = amp*.75\n",
    "        lift = lift*(i+1)\n",
    "        overtones.append(amp*np.cos(2*np.pi*lift*octave*FREQUENCY_VALUES[over_pitch]*time))\n",
    "        \n",
    "    overtones.append(fundamental)\n",
    "    \n",
    "    to_sum = zip(*overtones)\n",
    "    \n",
    "    return [sum(item) for item in to_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9860bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE COMPLEX LAYER\n",
    "\n",
    "##INPUT: a pitch set (string); a duration (int); a local duration, smaller than duration (int)\n",
    "##       an amplitude value (float); an octave (float); sampling frequency; complexity (int)\n",
    "##FUNCTION: - divides duration by local duration to determine number of iterations\n",
    "##          - for each iteration it creates a time vector, creates a window (envelope) and\n",
    "##            appends to the output array the output of create_sound (a complex tone)\n",
    "##          - flattens the list of complex sounds into a long list of multiple complex sounds\n",
    "##OUTPUT: a list of amplitude values representing a complex layer of a landscape\n",
    "def create_complex_layer(pitch_set, duration, local_dur, amplitude, octave, fs, complexity):\n",
    "    tones = []\n",
    "    for i in range(round(duration/local_dur)):\n",
    "        \n",
    "        time = np.arange(0,local_dur,1/fs)\n",
    "        window = np.hamming(len(time))\n",
    "        #window = random_adsr(len(time), .05, .25, .65, .05, fs)\n",
    "        tones.append(window*amplitude*create_sound(pitch_set, octave, local_dur, fs, complexity))\n",
    "        \n",
    "    return flatten(tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13070af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##VARIABLY SIZED LANDSCAPE\n",
    "\n",
    "##INPUT: a pitch set (string); local_dur (int); amplitude (float); octave (float); sampling frequency\n",
    "##       number of layers (int); possible complexity range (array of ints)\n",
    "##FUNCTION: - creates a list of durations with each successive duration being half of the previous\n",
    "##          - creates a list of amplitudes with each successive one being deteremined by 1/n\n",
    "##          - chop of these lists to contain local_dur and all durations/amplitudes smaller than it\n",
    "##          - for each layer in the number of layers, set overall duration, set local duration\n",
    "##            set octave, set amplitude and randomly choose complexity from range; then run\n",
    "##            create_complex_layer with these values and append to output list\n",
    "##          - zip the list of layers into one big landscape\n",
    "##OUTPUT: the complete landscape made up of many layers of oscillators\n",
    "##\n",
    "##NOTE: This is pretty poorly designed. The durations/amplitudes are hard coded and builds into\n",
    "##      each successive layer that the amplitude will be 1/n and duration will be half of the previous\n",
    "##      would be better to make this a variable at the main function level\n",
    "def variably_sized_landscape(pitch_set, local_dur, amplitude, octave, fs, layers, complexities):\n",
    "    landscape = []\n",
    "    \n",
    "    DURS = [local_dur/(2**x) for x in range(0,11)]\n",
    "    AMPS = [amplitude/x for x in range(1,12)]\n",
    "    \n",
    "    for i in range(len(DURS)):\n",
    "        dur = DURS[i]\n",
    "        if dur == local_dur:\n",
    "            durations = DURS[i:]\n",
    "            amplitudes = AMPS[i:]\n",
    "    \n",
    "    if layers > len(durations):\n",
    "        print('Please adjust your layers to be smaller than the number of durations')\n",
    "    \n",
    "    for i in range(layers):\n",
    "        duration = durations[0]\n",
    "        local_dur = durations[i]\n",
    "        octav = octave*(2**i)\n",
    "        amplitude = amplitudes[i]\n",
    "        complexity = random.sample(complexities, k=1)[0]\n",
    "        landscape.append(create_complex_layer(pitch_set, duration, local_dur, amplitude, octav, fs, complexity))\n",
    "    \n",
    "    to_sum = zip(*landscape)\n",
    "    return [sum(item) for item in to_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbe4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -r 1 -n 1\n",
    "\n",
    "## Composition\n",
    "from IPython.display import Audio\n",
    "\n",
    "SAMPLING_FREQUENCY = 44100\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "## preporatory work: load pitch sets; build distance matrix; create random walk\n",
    "## NOTE: sorted drunkards is simply sorting the pitch set to make it so it's in order of\n",
    "##       ascending pitch class\n",
    "    pitch_sets = create_pitch_sets(\n",
    "        FULL_PITCH_SETS\n",
    "    )\n",
    "    distance_matrix = create_distance_matrix(pitch_sets)\n",
    "    drunkards_walking_music = create_drunkards_walking_music(\n",
    "        pitch_sets, \n",
    "        distance_matrix\n",
    "    )\n",
    "    sorted_drunkards = [sorted(item) for item in drunkards_walking_music]\n",
    "    \n",
    "## create arrays for multichannel output; in this case, stereo\n",
    "    oscillator_list_l = []\n",
    "    oscillator_list_r = []\n",
    "    \n",
    "##BULK OF COMPOSITIONS\n",
    "##Rhythm: for each channel, hard code an array of lengths\n",
    "    counts = [1,2,3,4,5,6,7,8,9,10,11,11,10,9,8,7,6,5,4,3,2,1]\n",
    "    counts = [1,2,3,4,5,4,3,2,1]\n",
    "    #counts2 = [8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8]\n",
    "    count = 1\n",
    "\n",
    "##Octave displacement: create a set of octaves; 1 is A440, so this goes both above and below\n",
    "    octaves = [\n",
    "        .0625,\n",
    "        .125,\n",
    "        .25,\n",
    "        .5,\n",
    "        1,\n",
    "        2,\n",
    "        4,\n",
    "        8,\n",
    "        16,\n",
    "        32,\n",
    "        64\n",
    "        ]\n",
    "    \n",
    "##Rhythm\n",
    "    time1 = [x + random.randint(1,20) for x in np.zeros(ITERATIONS+1)]\n",
    "    time2 = random.sample(time1, k=len(time1))\n",
    "    \n",
    "    for pitch_set in sorted_drunkards:\n",
    "        octave1 = random.sample(octaves, k=1)[0]\n",
    "        #octave2 = random.sample(octaves, k=1)[0]\n",
    "        oscillator_list_l.append(variably_sized_landscape(pitch_set, 20, 1/counts[count-1], .0625, 44100, counts[count-1], [(item+1) for item in list(range(counts[count-1]))]))\n",
    "        #oscillator_list_r.append(variably_sized_landscape(pitch_set, time2[count-1], 1/octave2*8, octave2, 44100, counts2[count-1], [(item+1) for item in list(range(counts2[count-1]))]))\n",
    "        count += 1\n",
    "    \n",
    "    comp_length = len(flatten(oscillator_list_l))\n",
    "    #WINDOW1 = random_adsr(comp_length, .2, .2, .3, .3, 44100)\n",
    "    WINDOW2 = np.hamming(len(flatten(oscillator_list_l)))\n",
    "    \n",
    "Audio([WINDOW2*flatten(oscillator_list_l)],rate=SAMPLING_FREQUENCY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36fdd9",
   "metadata": {},
   "source": [
    "# UPDATED DISTANCE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81838738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATED DISTANCE METRIC INCORPORATING INTERSECTION, MANHATTAN & EUCLIDEAN\n",
    "#UPDATED ALSO TO INCORPORATE VARIABLE INPUT (INTEGER, RATIO, HERTZ)\n",
    "\n",
    "def create_new_distance_matrix(pitch_sets):\n",
    "    distance_matrix = []\n",
    "    for i in range(len(pitch_sets)):\n",
    "        row = []\n",
    "        static_set = pitch_set[i]\n",
    "        for j in range(len(pitch_sets)):\n",
    "            ##comparison algorithm changed\n",
    "            comp_set = pitch_sets[j]\n",
    "            static_leftover, comp_leftover = remainder_after_intersection(static_set, comp_set)\n",
    "            ##if the remainder is empty for both (i.e. they are the same set), give a value of 1\n",
    "            if not static_leftover and not comp_leftover:\n",
    "                ## score = 0 means it could never go to itself -- might be worth considering\n",
    "                ## score = 100 means very low probability\n",
    "                ## score = 1 means very high probability\n",
    "                score = 1\n",
    "            else:\n",
    "                ## if the two leftovers are of different sizes -- what should the score be?\n",
    "                ## Case1: extra notes are treated as nothing (generating voices does not take energy)\n",
    "                ## Case2: extra notes need to find the nearest neighbor to collapse or expand to (all voices are maintained)\n",
    "                ## Case3: unbalanced; if static > comp, note off events (losing a voice) don't take energy;\n",
    "                ##        if comp > static, note on events (adding a voice) do take energy and need to have a neighbor to come from\n",
    "                ## Case3 can be flipped if desired\n",
    "                ##\n",
    "                ## I think these rules make sense: if you can maintain common tones, do so. If you have leftover notes, existing voices\n",
    "                ## should be kept existing. This means that even if there is a note in set1 that is closer to a remainder note in set2\n",
    "                ## but it is not in the remainder of set1, then the leftover voices of both sets should be used to calculate distance.\n",
    "                ## The only cases extenuating for this rule is if there is an addition or subtraction of an additional voice. In this case,\n",
    "                ## any note in the opposite set can be used to \"split\" or \"collapse\" the voice.\n",
    "                ## \n",
    "                ## It is important to note that this system cannot be extended to different voices of chords at the moment. For\n",
    "                ## now, it assumes all chords are created equal in terms of voicing and instead cares about the collection of notes\n",
    "                ## more than how they are sounded. This is definitely something left to future work, as it would make more sense to\n",
    "                ## accomodate different voicings of chords (the distance function could be calculate simply by measuring the distance)\n",
    "                ## in frequency as opposed to divisions of the octave.\n",
    "                ##\n",
    "                ## Another important note is that the assumptions of this model assume equal distance within different divisions of \n",
    "                ## different spaces. This is obviously not the case but is used as a jumping off point for the building of this system.\n",
    "                ##\n",
    "                ## all that being said, here is the implementation of the most rudimentary version of this algorithm\n",
    "                if len(static_leftover) == len(comp_leftover):\n",
    "                    ## nuance of being equal in length: if two notes are equidistant from one note, or if they are both close\n",
    "                    ## to one note and not the other, how do we ensure the lowest possible score\n",
    "                    for item in static_leftover:\n",
    "                        return 0\n",
    "                \n",
    "            row.append(len(pitch_sets[i].intersection(pitch_sets[j])))\n",
    "        row_sum = sum(row)\n",
    "        row = np.array(row,dtype='f')/row_sum\n",
    "        row = np.cumsum(row)\n",
    "        distance_matrix.append(list(row))\n",
    "    return(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aac2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_map_and_score(set1, set2, TYPE, division = 12):\n",
    "    #make sure smallest set is used for comparisons\n",
    "    reverse_indicator = 1\n",
    "    if len(set1) > len(set2):\n",
    "        holder = set1[:]\n",
    "        set1 = set2[:]\n",
    "        set2 = holder[:]\n",
    "        reverse_indicator = -1\n",
    "        \n",
    "    ##Initiliaze outputs\n",
    "    mappings = []\n",
    "    score = 0\n",
    "    \n",
    "    #don't overwrite set2\n",
    "    comparison_set = set2[:]\n",
    "    \n",
    "    for note in set1:\n",
    "        smallest_distance = np.inf\n",
    "        for dest in comparison_set:\n",
    "            #distance function needs to be defined for specific input and units\n",
    "            dist = distance(note, dest, TYPE, division = division)\n",
    "            if dist < smallest_distance:\n",
    "                smallest_distance = dist\n",
    "                to_note = dest\n",
    "        tup_out = (note, to_note)\n",
    "        score += smallest_distance\n",
    "        comparison_set.remove(tup_out[1])\n",
    "        mappings.append(tup_out[::reverse_indicator])\n",
    "        \n",
    "    leftover = comparison_set\n",
    "    return (mappings, score, leftover)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = [0, 1, 2]\n",
    "set2 = [3, 4, 5]\n",
    "\n",
    "def distance(note1, note2, note_type, division = 12):\n",
    "    if note_type == \"int\":\n",
    "        return min(abs(note1-note2), division - abs(note1-note2))\n",
    "    elif note_type == \"ratio\":\n",
    "        return abs(note1-note2)\n",
    "    elif note_type == 'hertz':\n",
    "        return abs(np.log2(note1) - np.log2(note2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function assumes equal friction for adding and removing voices\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def minimum_distance_mapping(set1, set2, TYPE, division = 12):\n",
    "    ## set 1 should be smaller than set2 if different sizes\n",
    "    reverse_indicator = 1\n",
    "    if len(set1) > len(set2):\n",
    "        holder = set1[:]\n",
    "        set1 = set2[:]\n",
    "        set2 = holder[:]\n",
    "        reverse_indicator = -1\n",
    "    maps_and_scores = []\n",
    "    set1_orderings = list(itertools.permutations(set1))\n",
    "    for combination in set1_orderings:\n",
    "        combination = list(combination)\n",
    "        maps_and_scores.append(find_map_and_score(combination, set2, TYPE, division=division))\n",
    "    \n",
    "    lowest_score = np.inf\n",
    "    for map_and_score in maps_and_scores:\n",
    "        current_score = map_and_score[1]\n",
    "        current_map = map_and_score[0]\n",
    "        current_leftover = map_and_score[2]\n",
    "        if current_score < lowest_score:\n",
    "            lowest_score = current_score\n",
    "            best_map = current_map\n",
    "            leftover = current_leftover\n",
    "    \n",
    "    ## this is where it gets a little bit tricky again\n",
    "    ## should I have the leftover notes be allowed to go to the same note in the other set?\n",
    "    ## or should we only allow one additional voice be connected to a shared note\n",
    "    ## the latter seems more reasonable, but theoretically both are possible\n",
    "    \n",
    "    ## I will do the latter for now but the difference in code is just changing one call to \n",
    "    ## find_map_and_score to multiple individual calls\n",
    "    ## more efficient to do the latter actually, but could be a cooler compositional effect doing the former\n",
    "    ## actually it's more efficient to do the former, as the latter requires more permutations to be done\n",
    "    ## but that is okay for now\n",
    "    \n",
    "    if len(leftover) != 0:\n",
    "        while len(best_map) != len(set2):\n",
    "            leftover_orderings = list(itertools.permutations(leftover))\n",
    "            leftover_maps_and_scores = []\n",
    "            for combination in leftover_orderings:\n",
    "                combination = list(combination)\n",
    "                leftover_maps_and_scores.append(find_map_and_score(combination, set1, TYPE, division = division))\n",
    "\n",
    "            leftover_lowest = np.inf\n",
    "            for leftover_map_and_score in leftover_maps_and_scores:\n",
    "                leftover_map = leftover_map_and_score[0]\n",
    "                leftover_score = leftover_map_and_score[1]\n",
    "                leftover_leftover = leftover_map_and_score[2]\n",
    "                if leftover_score < leftover_lowest:\n",
    "                    leftover_lowest_score = leftover_score\n",
    "                    best_leftover_map = [tup[::-1] for tup in leftover_map]\n",
    "                    leftover = leftover_leftover\n",
    "            best_map = best_map + best_leftover_map\n",
    "            lowest_score += leftover_lowest_score\n",
    "    \n",
    "    final_map = [tup[::reverse_indicator] for tup in best_map]\n",
    "    final_score = lowest_score \n",
    "    \n",
    "    return (final_map, final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1084c",
   "metadata": {},
   "source": [
    "# EXPERIMENTS IN WINDOWING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f885d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiments in windowing\n",
    "## we have attack, decay, sustain and release\n",
    "## each of these things should be an array of values that follow some equation\n",
    "## attack -- should start low (0) and end high\n",
    "## decay -- needs to start where attack ends and fall \n",
    "## sustain -- should start where decay ends and be steady state\n",
    "## release -- should start where sustain ends and end low (0)\n",
    "##\n",
    "## use linspace/logspace/geomspace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "attack = np.geomspace(0.001, 1.0, num = 100, endpoint = False)\n",
    "decay = np.geomspace(1.0, 0.65, num = 50, endpoint = False)\n",
    "\n",
    "fs = 44100\n",
    "time = np.arange(0, 1/fs*200, 1/fs)\n",
    "sustain = .05*np.sin(2*np.pi*20000*time) + decay[-1]\n",
    "\n",
    "release = np.geomspace(sustain[-1], 0.001, num = 75, endpoint = True)\n",
    "plt.plot(np.concatenate((attack, decay, sustain, release)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c928d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## take length of array and divide it into four unequal parts\n",
    "##\n",
    "## get length of array -- should be an int\n",
    "length = 100\n",
    "\n",
    "attack_max_endpoint = length*.2\n",
    "decay_max_endpoint = length*.1\n",
    "sustain_max_endpoint = length*.6\n",
    "release_max_endpoint = length*.1\n",
    "\n",
    "attack_end = int(np.ceil(random.uniform(.5,1)*attack_max_endpoint))\n",
    "decay_end = int(np.ceil(random.uniform(.5,1)*decay_max_endpoint))\n",
    "sustain_end = int(np.ceil(random.uniform(.5,1)*sustain_max_endpoint))\n",
    "release_end = 100 - (attack_end + decay_end + sustain_end)\n",
    "\n",
    "print(attack_end)\n",
    "print(decay_end)\n",
    "print(sustain_end)\n",
    "print(release_end)\n",
    "\n",
    "attack = np.geomspace(0.001, random.uniform(.8,1), num = attack_end, endpoint = True)\n",
    "decay = np.geomspace(attack[-1], random.uniform(.4,.8), num = decay_end, endpoint = False)\n",
    "\n",
    "fs = 44100\n",
    "time = np.arange(0, 1/fs*sustain_end, 1/fs)\n",
    "sustain = random.uniform(.05,.1)*np.sin(2*np.pi*random.randint(17000,20000)*time) + decay[-1]\n",
    "\n",
    "release = np.geomspace(sustain[-1], 0.001, num = release_end, endpoint = False)\n",
    "plt.plot(np.concatenate((attack, decay, sustain, release)))\n",
    "print(len(np.concatenate((attack, decay, sustain, release))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deafde29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##make it a function -- ranges are doubles to express proportion of \n",
    "##input signal\n",
    "##Thing to improve: sustain parameters could be input, particularly frequency\n",
    "def random_adsr(array_length, a_range, d_range, s_range, r_range, fs):\n",
    "    length = array_length\n",
    "\n",
    "    attack_max_endpoint = length*a_range\n",
    "    decay_max_endpoint = length*d_range\n",
    "    sustain_max_endpoint = length*s_range\n",
    "    release_max_endpoint = length*r_range\n",
    "\n",
    "    attack_end = int(np.ceil(random.uniform(0,1)*attack_max_endpoint))\n",
    "    decay_end = int(np.ceil(random.uniform(0,1)*decay_max_endpoint))\n",
    "    sustain_end = int(np.ceil(random.uniform(0,1)*sustain_max_endpoint))\n",
    "    release_end = length - (attack_end + decay_end + sustain_end)\n",
    "\n",
    "    attack = np.geomspace(0.001, random.uniform(.8,1), num = attack_end, endpoint = True)\n",
    "    decay = np.geomspace(attack[-1], random.uniform(.4,.8), num = decay_end, endpoint = False)\n",
    "\n",
    "    time = np.arange(0, 1/fs*sustain_end, 1/fs)\n",
    "    sustain = random.uniform(.05,.1)*np.sin(2*np.pi*random.randint(17000,20000)*time) + decay[-1]\n",
    "    \n",
    "    release = np.geomspace(sustain[-1], 0.001, num = release_end, endpoint = True)\n",
    "    \n",
    "    to_return = np.concatenate((attack, decay, sustain, release))\n",
    "    \n",
    "    return np.concatenate((attack, decay, sustain, release))[0:length]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

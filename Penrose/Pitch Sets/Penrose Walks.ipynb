{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911c8978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def create_old_distance_matrix(pitch_sets):\n",
    "    distance_matrix = []\n",
    "    for i in range(len(pitch_sets)):\n",
    "        row = []\n",
    "        for j in range(len(pitch_sets)):\n",
    "            row.append(len(list_intersection(pitch_sets[i],pitch_sets[j])))\n",
    "        row_sum = sum(row)\n",
    "        row = np.array(row,dtype='f')/row_sum\n",
    "        row = np.cumsum(row)\n",
    "        distance_matrix.append(list(row))\n",
    "    return(distance_matrix)\n",
    "\n",
    "def list_intersection(list1, list2):\n",
    "    list3 = [value for value in list1 if value in list2]\n",
    "    return list3\n",
    "\n",
    "def remainder_after_intersection(list1, list2):\n",
    "    list3 = [x for x in list1 if x not in list2]\n",
    "    list4 = [x for x in list2 if x not in list1]\n",
    "    return list3, list4\n",
    "\n",
    "def closest_element_to_input(list1, myNumber):\n",
    "    return min(list1, key=lambda x:abs(x-myNumber))\n",
    "\n",
    "def create_new_distance_matrix(pitch_sets):\n",
    "    distance_matrix = []\n",
    "    for i in range(len(pitch_sets)):\n",
    "        row = []\n",
    "        for j in range(len(pitch_sets)):\n",
    "            ##comparison algorithm changed\n",
    "            static_set = pitch_set[i]\n",
    "            comp_set = pitch_sets[j]\n",
    "            static_leftover, comp_leftover = remainder_after_intersection(static_set, comp_set)\n",
    "            ##if the remainder is empty for both (i.e. they are the same set), give a value of 1\n",
    "            if not static_leftover and not comp_leftover:\n",
    "                ## score = 0 means it could never go to itself -- might be worth considering\n",
    "                ## score = 100 means very low probability\n",
    "                ## score = 1 means very high probability\n",
    "                score = 1\n",
    "            else:\n",
    "                ## if the two leftovers are of different sizes -- what should the score be?\n",
    "                ## Case1: extra notes are treated as nothing (generating voices does not take energy)\n",
    "                ## Case2: extra notes need to find the nearest neighbor to collapse or expand to (all voices are maintained)\n",
    "                ## Case3: unbalanced; if static > comp, note off events (losing a voice) don't take energy;\n",
    "                ##        if comp > static, note on events (adding a voice) do take energy and need to have a neighbor to come from\n",
    "                ## Case3 can be flipped if desired\n",
    "                ##\n",
    "                ## I think these rules make sense: if you can maintain common tones, do so. If you have leftover notes, existing voices\n",
    "                ## should be kept existing. This means that even if there is a note in set1 that is closer to a remainder note in set2\n",
    "                ## but it is not in the remainder of set1, then the leftover voices of both sets should be used to calculate distance.\n",
    "                ## The only cases extenuating for this rule is if there is an addition or subtraction of an additional voice. In this case,\n",
    "                ## any note in the opposite set can be used to \"split\" or \"collapse\" the voice.\n",
    "                ## \n",
    "                ## It is important to note that this system cannot be extended to different voices of chords at the moment. For\n",
    "                ## now, it assumes all chords are created equal in terms of voicing and instead cares about the collection of notes\n",
    "                ## more than how they are sounded. This is definitely something left to future work, as it would make more sense to\n",
    "                ## accomodate different voicings of chords (the distance function could be calculate simply by measuring the distance)\n",
    "                ## in frequency as opposed to divisions of the octave.\n",
    "                ##\n",
    "                ## Another important note is that the assumptions of this model assume equal distance within different divisions of \n",
    "                ## different spaces. This is obviously not the case but is used as a jumping off point for the building of this system.\n",
    "                ##\n",
    "                ## all that being said, here is the implementation of the most rudimentary version of this algorithm\n",
    "                if len(static_leftover) == len(comp_leftover):\n",
    "                    ## nuance of being equal in length: if two notes are equidistant from one note, or if they are both close\n",
    "                    ## to one note and not the other, how do we ensure the lowest possible score\n",
    "                    for item in static_leftover:\n",
    "                        return 0\n",
    "                \n",
    "            row.append(len(pitch_sets[i].intersection(pitch_sets[j])))\n",
    "        row_sum = sum(row)\n",
    "        row = np.array(row,dtype='f')/row_sum\n",
    "        row = np.cumsum(row)\n",
    "        distance_matrix.append(list(row))\n",
    "    return(distance_matrix)\n",
    "\n",
    "#sublists are not in normal form (i.e., the same intervals can be allowed)\n",
    "def findsubsets(s, n):\n",
    "    return list(itertools.combinations(s, n))\n",
    "\n",
    "#created limited sets based on specific axes\n",
    "def limitedsets(max_int, axes, vertices):\n",
    "    if len(axes) != vertices:\n",
    "        return \"You inputed things wrong! Make sure axes and vertices are the same\"\n",
    "    else:\n",
    "        limited_sets = []\n",
    "        first_set = [1]\n",
    "        for i in range(1, len(axes)):\n",
    "            first_set.append(first_set[i-1] + axes[i-1])\n",
    "            \n",
    "        limited_sets.append(first_set)\n",
    "        for i in range(1, max_int):\n",
    "            new_set = [(element + i) % max_int for element in first_set]\n",
    "            limited_sets.append(new_set)\n",
    "    return limited_sets\n",
    "\n",
    "def create_drunkards_walking_music(pitch_sets, distance_matrix):\n",
    "    current_set = random.randint(0,len(pitch_sets)-1)\n",
    "    drunkards_walking_music = [pitch_sets[current_set]]\n",
    "    for i in range(ITERATIONS):\n",
    "        r = random.uniform(0,1)\n",
    "        j = 0\n",
    "        while distance_matrix[current_set][j] < r:\n",
    "            j +=1\n",
    "        drunkards_walking_music.append(list(pitch_sets[j]))\n",
    "        current_set = j\n",
    "    return(drunkards_walking_music)\n",
    "\n",
    "##Self defined flatten function for ease of use\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad9f51e",
   "metadata": {},
   "source": [
    "# Implementation 1\n",
    "## Each shape has all possible subsets of frequency division of size VERTICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a22c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "##Pentagon\n",
    "pVERTICES = 5\n",
    "pDIVISIONS = 15\n",
    "\n",
    "p_master_set = np.arange(1,pDIVISIONS+1)\n",
    "\n",
    "p_subsets = findsubsets(p_master_set, pVERTICES)\n",
    "\n",
    "p_limited_subsets = limitedsets(max(p_master_set), [1,2,3,4,5], pVERTICES)\n",
    "#print(p_limited_subsets)\n",
    "\n",
    "##Diamond\n",
    "dVERTICES = 4\n",
    "dDIVISIONS = [8, 10, 12, 14, 16]\n",
    "\n",
    "d_master_set1 = np.arange(1,dDIVISIONS[0])\n",
    "d_master_set2 = np.arange(1,dDIVISIONS[1])\n",
    "d_master_set3 = np.arange(1,dDIVISIONS[2])\n",
    "d_master_set4 = np.arange(1,dDIVISIONS[3])\n",
    "d_master_set5 = np.arange(1,dDIVISIONS[4])\n",
    "\n",
    "diamond_subsets1 = findsubsets(d_master_set1, dVERTICES)\n",
    "diamond_subsets2 = findsubsets(d_master_set2, dVERTICES)\n",
    "diamond_subsets3 = findsubsets(d_master_set3, dVERTICES)\n",
    "diamond_subsets4 = findsubsets(d_master_set4, dVERTICES)\n",
    "diamond_subsets5 = findsubsets(d_master_set5, dVERTICES)\n",
    "\n",
    "d_limited_subsets1 = limitedsets(max(d_master_set1), [1,3,1,3], dVERTICES)\n",
    "d_limited_subsets2 = limitedsets(max(d_master_set2), [1,4,1,4], dVERTICES)\n",
    "d_limited_subsets3 = limitedsets(max(d_master_set3), [2,4,2,4], dVERTICES)\n",
    "d_limited_subsets4 = limitedsets(max(d_master_set4), [5,2,5,2], dVERTICES)\n",
    "d_limited_subsets5 = limitedsets(max(d_master_set5), [3,5,3,5], dVERTICES)\n",
    "#print(diamond_limited_subsets5)\n",
    "\n",
    "##Boat\n",
    "bVERTICES = 7\n",
    "bDIVISIONS = [17, 19, 21, 23, 25]\n",
    "\n",
    "b_master_set1 = np.arange(1,bDIVISIONS[0])\n",
    "b_master_set2 = np.arange(1,bDIVISIONS[1])\n",
    "b_master_set3 = np.arange(1,bDIVISIONS[2])\n",
    "b_master_set4 = np.arange(1,bDIVISIONS[3])\n",
    "b_master_set5 = np.arange(1,bDIVISIONS[4])\n",
    "\n",
    "b_subsets1 = findsubsets(b_master_set1, bVERTICES)\n",
    "b_subsets2 = findsubsets(b_master_set2, bVERTICES)\n",
    "b_subsets3 = findsubsets(b_master_set3, bVERTICES)\n",
    "b_subsets4 = findsubsets(b_master_set4, bVERTICES)\n",
    "b_subsets5 = findsubsets(b_master_set5, bVERTICES)\n",
    "\n",
    "b_limited_subsets1 = limitedsets(max(b_master_set1), [2,1,3,1,4,1,5], bVERTICES)\n",
    "b_limited_subsets2 = limitedsets(max(b_master_set2), [3,2,4,2,5,2,1], bVERTICES)\n",
    "b_limited_subsets3 = limitedsets(max(b_master_set3), [4,3,5,3,1,3,2], bVERTICES)\n",
    "b_limited_subsets4 = limitedsets(max(b_master_set4), [5,4,1,4,2,4,3], bVERTICES)\n",
    "b_limited_subsets5 = limitedsets(max(b_master_set5), [1,5,2,5,3,5,4], bVERTICES)\n",
    "#print(boat_limited_subsets1)\n",
    "\n",
    "##Star\n",
    "sVERTICES = 10\n",
    "sDIVISIONS = 30\n",
    "\n",
    "s_master_set = np.arange(1,sDIVISIONS+1)\n",
    "\n",
    "s_subsets = findsubsets(s_master_set, sVERTICES)\n",
    "\n",
    "s_limited_subsets = limitedsets(max(s_master_set), [4,3,5,4,1,5,2,1,3,2], sVERTICES)\n",
    "#print(s_limited_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce5222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create distance matrices for just limited subsets, using average divisions for both diamonds and boats\n",
    "##THIS USES OLD ALGORITHM FOR DISTANCE\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "##distance matrices\n",
    "p_distance_matrix = create_old_distance_matrix(p_limited_subsets)\n",
    "d_distance_matrix3 = create_old_distance_matrix(d_limited_subsets3)\n",
    "b_distance_matrix3 = create_old_distance_matrix(b_limited_subsets3)\n",
    "s_distance_matrix = create_old_distance_matrix(s_limited_subsets)\n",
    "\n",
    "ITERATIONS = 5\n",
    "\n",
    "##chord progression\n",
    "p_progression = create_drunkards_walking_music(p_limited_subsets, p_distance_matrix)\n",
    "d_progression = create_drunkards_walking_music(d_limited_subsets3, d_distance_matrix3)\n",
    "b_progression = create_drunkards_walking_music(b_limited_subsets3, b_distance_matrix3)\n",
    "s_progression = create_drunkards_walking_music(s_limited_subsets, s_distance_matrix)\n",
    "\n",
    "mdic = {\"p_progression\": p_progression, \"d_progression\": d_progression, \n",
    "        \"b_progression\": b_progression, \"s_progression\": s_progression}\n",
    "\n",
    "savemat(\"penrose_progressions.mat\", mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec42d629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-f76bc46774dd>:28: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  amp = 1/pitch\n",
      "<ipython-input-5-f76bc46774dd>:29: RuntimeWarning: invalid value encountered in multiply\n",
      "  wave = amp*window*np.sin(2*np.pi*pitch*ground*time)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "import soundfile as sf\n",
    "\n",
    "##GLOBAL PARAMETERS\n",
    "NUM_CHANNELS = 7\n",
    "NUM_LFE = 1\n",
    "GROUND_VALUES = [16.35, 32.70, 65.41, 130.81, 261.63]\n",
    "TIME_FIRMUS = [5, 4, 3, 2, 1, 1, 1, 2, 3, 4, 5] #proportion of total duration\n",
    "DURATION = 5 #mins\n",
    "FS = 48000\n",
    "\n",
    "\n",
    "##build audio files\n",
    "##pentagon audio files\n",
    "sorted_p = [sorted(item) for item in p_progression]\n",
    "for ground in GROUND_VALUES:\n",
    "    for i in range(len(sorted_p)):\n",
    "        pitch_set = sorted_p[i]\n",
    "        durations = {}\n",
    "        for j in range(len(pitch_set)):\n",
    "            durations[j] = random.sample(range(5, 10), 1)[0]\n",
    "        max_dur = max(durations.values())\n",
    "        for w in range(len(pitch_set)):\n",
    "            pitch = pitch_set[w]\n",
    "            duration = durations[w]\n",
    "            time = np.arange(0, duration, 1/FS)\n",
    "            window = np.hamming(len(time))\n",
    "            amp = 1/pitch\n",
    "            wave = amp*window*np.sin(2*np.pi*pitch*ground*time)\n",
    "            padding = max_dur*FS - duration*FS\n",
    "            if padding != 0:\n",
    "                front_pad = random.sample(range(0, int(np.floor(padding/2))),1)[0]\n",
    "                wave = np.pad(wave, (front_pad, padding-front_pad))\n",
    "            \n",
    "            filepath = str(ground)+ \"pent\" + str(i) + \"note\" + str(w+1) + \".wav\"\n",
    "            sf.write(filepath, wave, FS)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597866e6",
   "metadata": {},
   "source": [
    "Instead of exporting every single shape collection based on the markov model, instead, the markov model will be used in Matlab. All I need for Reaper (i.e. audio files) are each frequency at some duration for each division of the frequency space used. That's what I'll be doing below.\n",
    "\n",
    "So I realized that since I'm doing things spectrally, all I need to compute are the audio files for the star. This will cover all the other shapes' notes, since it's not a limiting of the frequency space but rather an additive exploration of it. It's a bit old school, frankly, and I probably could benefit from implementing my initial idea. But since time is pressing, we will do this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d682de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_VALUES = [16.35, 32.70, 65.41, 130.81, 261.63]\n",
    "FS = 48000\n",
    "\n",
    "from IPython.display import Audio\n",
    "import soundfile as sf\n",
    "\n",
    "##pentagon notes\n",
    "for ground in GROUND_VALUES:\n",
    "    for i in range(len(s_master_set)):\n",
    "        pitch = s_master_set[i]\n",
    "        frequency = ground*pitch\n",
    "        duration = 10\n",
    "        #while (duration < 10*FS):\n",
    "            #duration += frequency\n",
    "        #duration = np.round(duration/10)\n",
    "        time = np.arange(0, duration, 1/FS)\n",
    "        window = np.hamming(len(time))\n",
    "        amp = 1/pitch\n",
    "        wave = amp*window*np.sin(2*np.pi*pitch*ground*time)\n",
    "            \n",
    "        filepath = str(ground)+ \"note\" + str(i+1) + \".wav\"\n",
    "        sf.write(filepath, wave, FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b116f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 2.08333333e-05 4.16666667e-05 6.25000000e-05\n",
      " 8.33333333e-05 1.04166667e-04 1.25000000e-04 1.45833333e-04\n",
      " 1.66666667e-04 1.87500000e-04 2.08333333e-04 2.29166667e-04\n",
      " 2.50000000e-04 2.70833333e-04 2.91666667e-04 3.12500000e-04\n",
      " 3.33333333e-04 3.54166667e-04 3.75000000e-04 3.95833333e-04\n",
      " 4.16666667e-04 4.37500000e-04 4.58333333e-04 4.79166667e-04\n",
      " 5.00000000e-04 5.20833333e-04 5.41666667e-04 5.62500000e-04\n",
      " 5.83333333e-04 6.04166667e-04 6.25000000e-04 6.45833333e-04\n",
      " 6.66666667e-04 6.87500000e-04 7.08333333e-04 7.29166667e-04\n",
      " 7.50000000e-04 7.70833333e-04 7.91666667e-04 8.12500000e-04\n",
      " 8.33333333e-04 8.54166667e-04 8.75000000e-04 8.95833333e-04\n",
      " 9.16666667e-04 9.37500000e-04 9.58333333e-04 9.79166667e-04\n",
      " 1.00000000e-03 1.02083333e-03 1.04166667e-03 1.06250000e-03\n",
      " 1.08333333e-03 1.10416667e-03 1.12500000e-03 1.14583333e-03\n",
      " 1.16666667e-03 1.18750000e-03 1.20833333e-03 1.22916667e-03\n",
      " 1.25000000e-03 1.27083333e-03 1.29166667e-03 1.31250000e-03\n",
      " 1.33333333e-03 1.35416667e-03 1.37500000e-03 1.39583333e-03\n",
      " 1.41666667e-03 1.43750000e-03 1.45833333e-03 1.47916667e-03\n",
      " 1.50000000e-03 1.52083333e-03 1.54166667e-03 1.56250000e-03\n",
      " 1.58333333e-03 1.60416667e-03 1.62500000e-03 1.64583333e-03\n",
      " 1.66666667e-03 1.68750000e-03 1.70833333e-03 1.72916667e-03\n",
      " 1.75000000e-03 1.77083333e-03 1.79166667e-03 1.81250000e-03\n",
      " 1.83333333e-03 1.85416667e-03 1.87500000e-03 1.89583333e-03\n",
      " 1.91666667e-03 1.93750000e-03 1.95833333e-03 1.97916667e-03\n",
      " 2.00000000e-03 2.02083333e-03 2.04166667e-03 2.06250000e-03]\n",
      "[0.00000000e+00 2.08333333e-05 4.16666667e-05 6.25000000e-05\n",
      " 8.33333333e-05 1.04166667e-04 1.25000000e-04 1.45833333e-04\n",
      " 1.66666667e-04 1.87500000e-04 2.08333333e-04 2.29166667e-04\n",
      " 2.50000000e-04 2.70833333e-04 2.91666667e-04 3.12500000e-04\n",
      " 3.33333333e-04 3.54166667e-04 3.75000000e-04 3.95833333e-04\n",
      " 4.16666667e-04 4.37500000e-04 4.58333333e-04 4.79166667e-04\n",
      " 5.00000000e-04 5.20833333e-04 5.41666667e-04 5.62500000e-04\n",
      " 5.83333333e-04 6.04166667e-04 6.25000000e-04 6.45833333e-04\n",
      " 6.66666667e-04 6.87500000e-04 7.08333333e-04 7.29166667e-04\n",
      " 7.50000000e-04 7.70833333e-04 7.91666667e-04 8.12500000e-04\n",
      " 8.33333333e-04 8.54166667e-04 8.75000000e-04 8.95833333e-04\n",
      " 9.16666667e-04 9.37500000e-04 9.58333333e-04 9.79166667e-04\n",
      " 1.00000000e-03 1.02083333e-03 1.04166667e-03 1.06250000e-03\n",
      " 1.08333333e-03 1.10416667e-03 1.12500000e-03 1.14583333e-03\n",
      " 1.16666667e-03 1.18750000e-03 1.20833333e-03 1.22916667e-03\n",
      " 1.25000000e-03 1.27083333e-03 1.29166667e-03 1.31250000e-03\n",
      " 1.33333333e-03 1.35416667e-03 1.37500000e-03 1.39583333e-03\n",
      " 1.41666667e-03 1.43750000e-03 1.45833333e-03 1.47916667e-03\n",
      " 1.50000000e-03 1.52083333e-03 1.54166667e-03 1.56250000e-03\n",
      " 1.58333333e-03 1.60416667e-03 1.62500000e-03 1.64583333e-03\n",
      " 1.66666667e-03 1.68750000e-03 1.70833333e-03 1.72916667e-03\n",
      " 1.75000000e-03 1.77083333e-03 1.79166667e-03 1.81250000e-03\n",
      " 1.83333333e-03 1.85416667e-03 1.87500000e-03 1.89583333e-03\n",
      " 1.91666667e-03 1.93750000e-03 1.95833333e-03 1.97916667e-03\n",
      " 2.00000000e-03 2.02083333e-03 2.04166667e-03 2.06250000e-03]\n"
     ]
    }
   ],
   "source": [
    "FS = 48000\n",
    "\n",
    "duration = 0\n",
    "frequency = 110\n",
    "while (duration < 10*FS):\n",
    "    duration += frequency\n",
    "duration = np.round(duration/10)\n",
    "time = np.arange(0, duration, 1/FS)\n",
    "time2 = np.arange(0, 10, 1/FS)\n",
    "print(time[0:100])\n",
    "print(time2[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3cf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_distance_matrix(pitch_sets):\n",
    "    distance_matrix = []\n",
    "    for i in range(len(pitch_sets)):\n",
    "        row = []\n",
    "        static_set = pitch_set[i]\n",
    "        for j in range(len(pitch_sets)):\n",
    "            ##comparison algorithm changed\n",
    "            comp_set = pitch_sets[j]\n",
    "            static_leftover, comp_leftover = remainder_after_intersection(static_set, comp_set)\n",
    "            ##if the remainder is empty for both (i.e. they are the same set), give a value of 1\n",
    "            if not static_leftover and not comp_leftover:\n",
    "                ## score = 0 means it could never go to itself -- might be worth considering\n",
    "                ## score = 100 means very low probability\n",
    "                ## score = 1 means very high probability\n",
    "                score = 1\n",
    "            else:\n",
    "                ## if the two leftovers are of different sizes -- what should the score be?\n",
    "                ## Case1: extra notes are treated as nothing (generating voices does not take energy)\n",
    "                ## Case2: extra notes need to find the nearest neighbor to collapse or expand to (all voices are maintained)\n",
    "                ## Case3: unbalanced; if static > comp, note off events (losing a voice) don't take energy;\n",
    "                ##        if comp > static, note on events (adding a voice) do take energy and need to have a neighbor to come from\n",
    "                ## Case3 can be flipped if desired\n",
    "                ##\n",
    "                ## I think these rules make sense: if you can maintain common tones, do so. If you have leftover notes, existing voices\n",
    "                ## should be kept existing. This means that even if there is a note in set1 that is closer to a remainder note in set2\n",
    "                ## but it is not in the remainder of set1, then the leftover voices of both sets should be used to calculate distance.\n",
    "                ## The only cases extenuating for this rule is if there is an addition or subtraction of an additional voice. In this case,\n",
    "                ## any note in the opposite set can be used to \"split\" or \"collapse\" the voice.\n",
    "                ## \n",
    "                ## It is important to note that this system cannot be extended to different voices of chords at the moment. For\n",
    "                ## now, it assumes all chords are created equal in terms of voicing and instead cares about the collection of notes\n",
    "                ## more than how they are sounded. This is definitely something left to future work, as it would make more sense to\n",
    "                ## accomodate different voicings of chords (the distance function could be calculate simply by measuring the distance)\n",
    "                ## in frequency as opposed to divisions of the octave.\n",
    "                ##\n",
    "                ## Another important note is that the assumptions of this model assume equal distance within different divisions of \n",
    "                ## different spaces. This is obviously not the case but is used as a jumping off point for the building of this system.\n",
    "                ##\n",
    "                ## all that being said, here is the implementation of the most rudimentary version of this algorithm\n",
    "                if len(static_leftover) == len(comp_leftover):\n",
    "                    ## nuance of being equal in length: if two notes are equidistant from one note, or if they are both close\n",
    "                    ## to one note and not the other, how do we ensure the lowest possible score\n",
    "                    for item in static_leftover:\n",
    "                        return 0\n",
    "                \n",
    "            row.append(len(pitch_sets[i].intersection(pitch_sets[j])))\n",
    "        row_sum = sum(row)\n",
    "        row = np.array(row,dtype='f')/row_sum\n",
    "        row = np.cumsum(row)\n",
    "        distance_matrix.append(list(row))\n",
    "    return(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e83da71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_map_and_score(set1, set2, TYPE, division = 12):\n",
    "    #make sure smallest set is used for comparisons\n",
    "    reverse_indicator = 1\n",
    "    if len(set1) > len(set2):\n",
    "        holder = set1[:]\n",
    "        set1 = set2[:]\n",
    "        set2 = holder[:]\n",
    "        reverse_indicator = -1\n",
    "        \n",
    "    ##Initiliaze outputs\n",
    "    mappings = []\n",
    "    score = 0\n",
    "    \n",
    "    #don't overwrite set2\n",
    "    comparison_set = set2[:]\n",
    "    \n",
    "    for note in set1:\n",
    "        smallest_distance = np.inf\n",
    "        for dest in comparison_set:\n",
    "            #distance function needs to be defined for specific input and units\n",
    "            dist = distance(note, dest, TYPE, division = division)\n",
    "            if dist < smallest_distance:\n",
    "                smallest_distance = dist\n",
    "                to_note = dest\n",
    "        tup_out = (note, to_note)\n",
    "        score += smallest_distance\n",
    "        comparison_set.remove(tup_out[1])\n",
    "        mappings.append(tup_out[::reverse_indicator])\n",
    "        \n",
    "    leftover = comparison_set\n",
    "    return (mappings, score, leftover)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa20433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = [0, 1, 2]\n",
    "set2 = [3, 4, 5]\n",
    "\n",
    "def distance(note1, note2, note_type, division = 12):\n",
    "    if note_type == \"int\":\n",
    "        return min(abs(note1-note2), division - abs(note1-note2))\n",
    "    elif note_type == \"ratio\":\n",
    "        return abs(note1-note2)\n",
    "    elif note_type == 'hertz':\n",
    "        return abs(np.log2(note1) - np.log2(note2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27af41c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.33333333333333326\n",
      "1.0000000000000009\n"
     ]
    }
   ],
   "source": [
    "print(distance(0, 1, \"int\", division = 12))\n",
    "print(distance(4/3, 1/1, \"ratio\"))\n",
    "print(distance(200, 400, \"hertz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4ebe41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 3), (1, 4), (2, 5)], 9, [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_map_and_score(set1, set2, \"int\", division = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f40a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function assumes equal friction for adding and removing voices\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def minimum_distance_mapping(set1, set2, TYPE, division = 12):\n",
    "    ## set 1 should be smaller than set2 if different sizes\n",
    "    reverse_indicator = 1\n",
    "    if len(set1) > len(set2):\n",
    "        holder = set1[:]\n",
    "        set1 = set2[:]\n",
    "        set2 = holder[:]\n",
    "        reverse_indicator = -1\n",
    "    maps_and_scores = []\n",
    "    set1_orderings = list(itertools.permutations(set1))\n",
    "    for combination in set1_orderings:\n",
    "        combination = list(combination)\n",
    "        maps_and_scores.append(find_map_and_score(combination, set2, TYPE, division=division))\n",
    "    \n",
    "    lowest_score = np.inf\n",
    "    for map_and_score in maps_and_scores:\n",
    "        current_score = map_and_score[1]\n",
    "        current_map = map_and_score[0]\n",
    "        current_leftover = map_and_score[2]\n",
    "        if current_score < lowest_score:\n",
    "            lowest_score = current_score\n",
    "            best_map = current_map\n",
    "            leftover = current_leftover\n",
    "    \n",
    "    ## this is where it gets a little bit tricky again\n",
    "    ## should I have the leftover notes be allowed to go to the same note in the other set?\n",
    "    ## or should we only allow one additional voice be connected to a shared note\n",
    "    ## the latter seems more reasonable, but theoretically both are possible\n",
    "    \n",
    "    ## I will do the latter for now but the difference in code is just changing one call to \n",
    "    ## find_map_and_score to multiple individual calls\n",
    "    ## more efficient to do the latter actually, but could be a cooler compositional effect doing the former\n",
    "    ## actually it's more efficient to do the former, as the latter requires more permutations to be done\n",
    "    ## but that is okay for now\n",
    "    \n",
    "    if len(leftover) != 0:\n",
    "        while len(best_map) != len(set2):\n",
    "            leftover_orderings = list(itertools.permutations(leftover))\n",
    "            leftover_maps_and_scores = []\n",
    "            for combination in leftover_orderings:\n",
    "                combination = list(combination)\n",
    "                leftover_maps_and_scores.append(find_map_and_score(combination, set1, TYPE, division = division))\n",
    "\n",
    "            leftover_lowest = np.inf\n",
    "            for leftover_map_and_score in leftover_maps_and_scores:\n",
    "                leftover_map = leftover_map_and_score[0]\n",
    "                leftover_score = leftover_map_and_score[1]\n",
    "                leftover_leftover = leftover_map_and_score[2]\n",
    "                if leftover_score < leftover_lowest:\n",
    "                    leftover_lowest_score = leftover_score\n",
    "                    best_leftover_map = [tup[::-1] for tup in leftover_map]\n",
    "                    leftover = leftover_leftover\n",
    "            best_map = best_map + best_leftover_map\n",
    "            lowest_score += leftover_lowest_score\n",
    "    \n",
    "    final_map = [tup[::reverse_indicator] for tup in best_map]\n",
    "    final_score = lowest_score \n",
    "    \n",
    "    return (final_map, final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088fe7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 5, 7, 9), (4, 5, 9, 7), (4, 7, 5, 9), (4, 7, 9, 5), (4, 9, 5, 7), (4, 9, 7, 5), (5, 4, 7, 9), (5, 4, 9, 7), (5, 7, 4, 9), (5, 7, 9, 4), (5, 9, 4, 7), (5, 9, 7, 4), (7, 4, 5, 9), (7, 4, 9, 5), (7, 5, 4, 9), (7, 5, 9, 4), (7, 9, 4, 5), (7, 9, 5, 4), (9, 4, 5, 7), (9, 4, 7, 5), (9, 5, 4, 7), (9, 5, 7, 4), (9, 7, 4, 5), (9, 7, 5, 4)]\n",
      "[(7, 5, 4), (7, 4, 5), (5, 7, 4), (5, 4, 7), (4, 7, 5), (4, 5, 7)]\n",
      "[(5, 7), (7, 5)]\n",
      "[(5,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(0, 1), (0, 9), (0, 4), (0, 7), (0, 5)], 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = [0,]\n",
    "set2 = [1, 4, 5, 7, 9]\n",
    "TYPE = \"int\"\n",
    "\n",
    "minimum_distance_mapping(set1, set2, TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440883f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d712e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
